{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Computer Memory\n",
    ">Cogworks 2018  (AJ Federici)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Hardware\n",
    "\n",
    "### 1.1 Possibly the greatest invention of all time - The Transistor\n",
    "\n",
    "A transistor is information itself. There are probably around two billion in your phone thanks to the minute scale that we are able to manufacture down to these days.  The magic behind this is all thanks to the semiconducting properties of silicon, which you may have heard of as being important in the tech industry, hence Silicon Valley.  Back to the point - one silicon bonds with 4 others to create a nice covalent structure.  Now, as a semiconductor it has the ability to both allow the flow of electrons, therefore conducting, but also to not allow this flow and be non-conducting. To enhance these properties a technique known as doping, or introducing a foreing substance to enhance performance is done.  Simply put, the introduction of a small amount of phosphorous allows for extra electrons to flow and we will call this N-type.  The introduction of a small amount of boron leaves holes that electrons want to fill and we will call the P-type.\n",
    "\n",
    "(NOTE - N-type and P-type are both neutrally charged, one just favors the flow of electrons while the other favors the flow of \"holes\" or spaces that seek electrons)\n",
    "\n",
    "### 1.15 Extra \n",
    "\n",
    "Transistors aren't the one all be all of a computer, other things like capacitors are also necessary as an example.  A capacitor conditions DC voltage to other components (e.g. the video card, hard drive, sound card etc) as a way to provide a steady stream of power. The amount of electricity from the outlet would fry everythhing.  Capacitors store charge, kind of like mini batteries all over the place\n",
    "\n",
    "### 1.2 Forming a transistor\n",
    "\n",
    "To aid in the explanation this is the layout of probably the most common type of transistor: NPN [image.png](attachment:image.png)\n",
    "\n",
    "Negative current from the electricity source flows into the first N layer.  Because this layer favors the flow of electrons they will diffuse into the P layer, where they will fill the holes that were seeking electrons.  Now, because the P layer was neutral and gained electrons it now has a repulsive effect to the other electrons still flowing from the electricity source.  In this state the transistor is 'off'.  To turn it 'on' and allowing for two different states, the basis for binary, is done by adding a positive charge to the gate.  When the gate has positive charge, the electrons flowing from the source of electricity are more attracted to the gate than they are repeled by the p-types now negative charge.  The turning on and off of the gate is what allows electrons to flow (on) or not (off) with no mechanical parts and it can be done extremely fast.  \n",
    "\n",
    "The importance of the transistor over say, vacuum tubes, is that they can be made remarkably small and require no moving parts or maintenance.  The increase on the amount of transistors makes computer chips faster and with moores law the amount of transistors doubles each year to allow for a reduction in size.  But, bringing the n and p type too close allows for quantam tunneling because of how small a scale we're talking about leaving not enough of a barrier to stop the flow of charge resulting in a switch that can't reliably be turned off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Binary Introduction\n",
    "\n",
    "So now that we are able to communicate two different stats for each transistor we can move on into the language of computers: binary.  A transistor without current flowing through will be assigned to 0 and one where the gate is on will be assigned 1.  We typically think in the number system known as decimal, so let's look at a comparison between counting in binary and counting in decimal to get a hang of it.\n",
    "\n",
    "0000 - 0\n",
    "0001 - 1\n",
    "0010 - 2\n",
    "0011 - 3\n",
    "0100 - 4\n",
    "0101 - 5 \n",
    "0110 - 6\n",
    "0111 - 7 \n",
    "1000 - 8\n",
    "\n",
    "(NOTE - a number begining in 1 followed only be zeros is 2^n-1 where n is the digit position of the 1)\n",
    "\n",
    "### 2.1 Boolean Algebra (Simple)\n",
    "\n",
    "So if we keep going with the powers of 2 rule we will end up with something like this\n",
    "\n",
    "1000 is 8\n",
    "10000 is 16\n",
    "100000 is 32\n",
    "1000000 is 64\n",
    "10000000 is 128\n",
    "11111111 is 255\n",
    "\n",
    "A single bit is one transistor (on or off)\n",
    "A byte is 8 bits and as you can see above, 255 is the largest number that can be represented with a byte\n",
    "\n",
    "We can also add in binary!!\n",
    "1 + 0 = 1\n",
    "0 + 0 = 0\n",
    "1 + 1 = 0 and carry a 1, just like regular addition incorparates the idea of a carry\n",
    "\n",
    "ex: \n",
    "\n",
    " 110110+ \n",
    " 111000 =\n",
    "1101110\n",
    "\n",
    "### 2.1 Numbers are nice but what about letters\n",
    "\n",
    "ASCII is how binar gets converted to letters.  Each character is just a byte in binary so there are a total of 255 symbols/letters to choose from.  For example, A is 01000001 in binary and different from a.  And, if just one character takes a byte, think about how many bytes you computer must be able to store!  Also keep in mind that this is in temporary storage with transistors; hard drives work differentyl in that the data gets written onto a spinning disk that can remain even if the machine is turned off.\n",
    " \n",
    "So, if a character is 1 byte, what's an int take up?\n",
    " \n",
    "Well, lets write a python command to investigate further.\n",
    " \n",
    "```\n",
    "\n",
    ">>> sys.getsizeof(int())\n",
    "24\n",
    "\n",
    "```\n",
    "\n",
    "24 may seem super large and you might ask why it isn't 8 or something. Well, remember that a Python int is very different from an int in (for example) C. In Python, an int is a fully-fledged object. This means there's extra overhead.\n",
    "\n",
    "Every Python object contains at least a refcount and a reference to the object's type in addition to other storage; on a 64-bit machine, that takes up 16 bytes on its own! Those 16 plus the 8 byes for the number itself account for all 24. \n",
    "\n",
    "\n",
    "### 2.2 The power of logic gates\n",
    "\n",
    "While being able to represent numbers using transistors is nice, its even cooler that we can represent logic gates with them.  Picture two transistors, each with an input and an output, and then imagine that we have a light bulb as well where it being on is 1 and off is 0.\n",
    "\n",
    "If we wire out first transistor's output into the next transistor's input and then hook up the second's output to the lightbulb an AND gate is formed.  An AND gate produces the value 1 IF the two inputs are both 1.  You can see how this works because even if current flows through the first one, if the second is off it will cut off both its own and the first's flow of electrons.\n",
    "\n",
    "The same physical wiring can be done for all the other logic gates like OR and NOT and so on.\n",
    "\n",
    "\n",
    "\n",
    "Challenge - Design an adding machine using AND and OR gates (Hint: You will also need to use a NOT gate which just flips the result of an output)\n",
    "\n",
    "Answer - NAND is just AND into a NOT\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Abstracting out to understand memory\n",
    "\n",
    "An Arithmetic Logic Unit does all the computers computation and is the result of how we used transistors in the above section\n",
    "\n",
    "If you attempted the challenge problem, you saw how complicated adding got using basic logic gates and we do the same thing for multiplication and division which get really really complicated.\n",
    "\n",
    "If transistors didn't seem powerful enough, you can also store information on them using logic gates as seen below!\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "The architecture above can store 1 bit of information. A group of these is called a register, which has an address in memory. It needs an adress because the registers are stored in a grid to save on the amount of wires.  Instead of say 256 wires flowing into each one if they were in a row you can make a 16x16 grid where each register is at the intersection of two wires. The address is where the intersection is just like a city kind of.  The adress is just the row then the column in binary.\n",
    "\n",
    "That grid, in this example, is a block of 256 bit memory.  These then get grouped togethether and the groupings form new groupings and those form groupings until you end up with your stick of RAM (Random Access Memory) and thus the memory adresses also get longer and longer.\n",
    "\n",
    "### 3.2 C++ Memory\n",
    "\n",
    "Now, before we get into how memory management works in python, let's talk about how it works in a lower level like C++ so we can begin to appreciate the simplicity python brings to the table.\n",
    "\n",
    "\n",
    "In C++, you define how much space things will take up before hand so that at compile time the right amount of memory is allocated in the stack (this will be discussed in the next section).  However, unlike python, you have to deal with memory management so if you want to do any dynamic memory allocation on the heap (also discussed in the next section) you have to make sure to also delete it on your own once you're done using it to avoid crashing your computer. To increase the size of your array you would create a new one that's larger and copy the data over and then delete the old one.  \n",
    "\n",
    "For example, you define both an array type and size before hand in c++ thus making each element contain arout 8 bytes instead of pythons 24 which is why lower level languages can be made much faster; not to mention, you can also directly access and manipulate addresses through the use of pointers.\n",
    "\n",
    "\n",
    "### 3.3 Stack and Heap\n",
    "\n",
    "Stack is used for static memory allocation and Heap for dynamic memory allocation, both are stored in the computer's RAM.\n",
    "\n",
    "Variables allocated on the stack are stored directly to the memory and access to this memory is very fast, and it's allocation is dealt with when the program is compiled. The stack, a data structure you mught be familiar with, is always reserved in a LIFO order, the last thing entered is the first thing executed. This makes it really simple to keep track of the stack, freeing a block from the stack is nothing more than adjusting one pointer.\n",
    "\n",
    "Variables allocated on the heap have their memory allocated at run time and accessing this memory is a bit slower, but the heap size is only limited by the size of virtual memory . Elements of the heap have no dependencies with each other, unlike the ordering within the stack, and can always be accessed randomly at any time. You can allocate a block at any time and free it at any time. This makes it much more complex to keep track of which parts of the heap are allocated or free at any given time\n",
    "\n",
    "Basically, you can use the stack if you know exactly how much data you need to allocate before compile time and it is not too big.\tYou can use heap if you don't know exactly how much data you will need at runtime or if you need to allocate a lot of data.\n",
    "\n",
    "For advanced applications overreliance on the heap can be a crucial speed block as multithreading allows the use of multiple stacks but only one heap.\n",
    "\n",
    "memory allocation stuff - The stack is much simpler to allocate and deallocate from the heap - both are places in memory but typically there is much more set aside in the stack, which is memory set aside as scrath space for a thread of execution\n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Python Memory\n",
    "\n",
    "Memory management in Python involves a private heap containing all Python objects and data structures. The management of this private heap is ensured internally by the Python memory manager, so even though it was mentiones that its much less straight foward to work with than the stack, we don't have to! Python has a memory manager that takes care of basically everything for us. The allocation of heap space for Python objects and other internal buffers is performed on demand by the Python memory manager through the Python/C API functions listed in this document.  A garbage collector is built in that will automatically delete data that isn't being reference i.e no pointer pointing at the memory address its housed in.  You just freely create objects and the language's memory manager periodically (or when you specifically direct it to) looks for any objects that are no longer referenced by your program.\n",
    "\n",
    "(NOTE - Python is the language and does not specify how exactly implementations must achieve the semantics defined by Python the language. Every implementation (CPython, PyPy, IronPython, Stackless, Jython...) is free to do its own thing!)\n",
    "\n",
    "In our case (CPython), all objects live on the private heap containing all Python objects and data structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Application (Images)\n",
    "\n",
    "Images in standard formats such as gif, tiff, and jpeg are\n",
    "stored so that each pixel value lies in the range [0,255]\n",
    "\n",
    "The range [0, 255] is chosen so that each pixel can be\n",
    "represented by 8 bits (one byte).\n",
    "– 0: Black (0% red, 0% green, 0% blue)\n",
    "– 128: Grey (50% red, 50% green, 50% blue)\n",
    "– 255: White (100% red, 100% green, 100% blue)\n",
    "\n",
    "Colour images will typically consist of three 2D arrays in the\n",
    "range [0 , 255] for each of the red, green, and blue channels which will then use 24 bits instead.\n",
    "\n",
    "Image operations such as multiplication become very expensive because since the numbers will most like overflow for 8 bits, everything needs to convert to a double which is 64 bit, 8 times as much!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Quantam Computing (extra content)\n",
    "\n",
    "Qubit - can be 0 or 1 or both instead of just 0 or 1 like a classical bit (binary digit).  Instead of transistor we look at spin of an elecrton, spin up, spin down, or both at once.  It can be both at once because before measuring it is in a quantam superpositon - It is in both states at once, each with its own probability for its state once it is measured.  But before measurement it is in both at the same time.\n",
    "\n",
    "2 Bits classical \n",
    "00\n",
    "01\n",
    "10\n",
    "11\n",
    "This is two bits of information, we can measure the value of first digit and the value of the second digit.\n",
    "\n",
    "In the case of two qubits we have (u for spin up and d for spin down)\n",
    "uu\n",
    "ud\n",
    "du\n",
    "dd\n",
    "\n",
    "(NOTE - The uu and dd are fine and have the classical equivalents 00 and 11 but the ud and du don't.  Basically they are in an entangled state where measuring one automatically informs you of the other.  They are coupled to each other)\n",
    "\n",
    "Now this seems to be the same amount of information, but in reality we have the same information for the OUTPUT.  Before measuring a result, which will be the same amount of information as classical bits, we actually have 4 bits of information during processing instead of two.  Two numbers are needed to represent the two bits, the first digit and the second digit.  For three bits we have three digits.  BUT for qubits we need 4 numbers to represent the 4 states because they all have a probability.  This results in 2^N relationship between N qubits and the equivalent number of bits.  \n",
    "\n",
    "\n",
    "Probabilistic and random problems become much simpler\n",
    "Binary logic isn’t always best and neither is quantam - it is likely you will still experience everyday things the same way because quantam computing can't replace regular computing. But, currently difficult problems such as simulating protein synthesis (I think) will become easy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
